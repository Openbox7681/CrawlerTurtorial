#!/usr/bin/python
# coding:utf-8
import sys
import os
from datetime import datetime
import calendar
import time
import json
import requests

import click
import schedule
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common import action_chains, keys  # keys.Keys
from selenium.webdriver.support.ui import WebDriverWait
from elasticsearch import Elasticsearch
from fake_useragent import UserAgent

from logContainer import LogsFunc

URL = "https://www.exploit-db.com"

def get_detail(web_url,result):
    res = requests.get(web_url, headers=headers)
    detail = BeautifulSoup(res.text, 'html.parser')
    cve_id_list = detail.find_all("div", {"class" : "card-body"})[0].find_all("h6")[1].find_all("a")
    if len(cve_id_list) == 0 :
        result['cve_id'] = "None"
    else:
        cve_id_list = [item.text.replace(" ","").strip() for item in cve_id_list]
        result['cve_id']=["CVE-"+(item) for item in cve_id_list]
    result['exploit_code_html'] =  str(detail.find_all("div", {"class" : "card-body"})[4])
    result['exploit_code'] =  str(detail.find_all("div", {"class" : "card-body"})[4].text)
    # print 'CVE_ID :' +result['cve_id']
    # print 'raw : ' + result['sourcecode']
    return result

def insert(html_source):
    soup = BeautifulSoup(html_source, 'html.parser')
    exploit_list = soup.find_all("tr", {"class":["odd","even"]})
    for exploit_index in range(len(exploit_list)):
        #ua = UserAgent()
        #headers = {'User-Agent': ua.random}
        try:
            result = dict()
            exploit = exploit_list[exploit_index].find_all("td")
            result['EDB_ID'] = exploit[4].find("a").get("href").split("/")[-1].strip()
            result['web_url'] = URL + exploit[4].find("a").get("href")
            result['author'] = exploit[7].text.strip()
            result['title'] = exploit[4].text.strip()
            result['vultype'] =  exploit[5].find("a").text.strip()
            result['platform'] =  exploit[6].find("a").text.strip()
            result['download_url'] = URL + exploit[1].find("a").get("href")
            Published_Time= str(exploit[0].text.strip())
            date = datetime.strptime(Published_Time, '%Y-%m-%d')

            year=date.year
            index_name = 'sec_exploitdb-'+str(year)
            try:
                mapping='{"settings": {"index.mapping.ignore_malformed": true}}'
                res = ES_ip.indices.create(index=index_name, body=mapping)
            except Exception as e :
                pass
                # print('--Error on line {}'.format(sys.exc_info()[-1].tb_lineno) + str(e))
            result['publish_date'] = calendar.timegm(datetime.timetuple(date)) * 1000

            result_id = result['EDB_ID']

            try:

                result = get_detail(result['web_url'], result)
                print('add or update : ',result['EDB_ID'])
                print('----------')

                res = ES_ip.index(index=index_name, doc_type='exploitdb', body=result, id=result_id)
            except Exception as e:
                # logsFunction.appendWrite('ascii error : '+result['EDB_ID'])
                print('--Error on line {}'.format(sys.exc_info()[-1].tb_lineno) + str(e))

            logsFunction.appendWrite('add or update : '+result['EDB_ID'])
            time.sleep(sleepTime)
        except Exception as e:
            logsFunction.appendWrite('ascii error : '+result['EDB_ID'])
            print('--Error on line {}'.format(sys.exc_info()[-1].tb_lineno) + str(e))


def get_exploitdb(chromedrive_path):

    
    if chromedrive_path is None:
        '''取得當下目錄'''
        current_path = os.path.abspath(__file__)
        '''取得chromedeiver路徑'''
        chromedrive_path=os.path.join(os.path.abspath(os.path.dirname(current_path) + os.path.sep ),'chromedriver')
    else:
        chromedrive_path = os.path.join(chromedrive_path, 'chromedriver')
    print(chromedrive_path)

    '''設置 webdriver參數'''
    options = webdriver.ChromeOptions()
    options.add_argument('--disable-dev-shm-usage')
    '''以headless方案運行'''
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')

    # create a new Chrome session
    global driver
    driver = webdriver.Chrome(chromedrive_path,options=options)

    ### setup
    totalPage = 20
    global sleepTime
    sleepTime=5
    ua = UserAgent(verify_ssl=False)
    global headers
    headers = {'User-Agent': ua.random}

    driver.implicitly_wait(30)
    driver.get(URL)
    wait = WebDriverWait(driver, 30)

    print("The total page : ",int(totalPage))
    try:
        for nowPage in range(totalPage):
            time.sleep(5)
            print('page:'+str(nowPage+1))
            html_source = driver.page_source
            insert(html_source)
            pageButton = driver.find_element_by_class_name('pagination').find_element_by_link_text(str(nowPage + 1))
            pageButton.click()
    except Exception as e:
        print('--Error on line {}'.format(sys.exc_info()[-1].tb_lineno) + str(e))

    ### close Chrome Driver
    driver.close()

@click.command()
@click.option('--es_ip', type=str,default='192.168.163.51')
@click.option('--es_port', type=str,default='59200')
@click.option('--chormdriver_path', type=str)
#120分鐘執行一次
def run(es_ip, es_port, chormdriver_path):
    global ES_ip
    ES_ip = Elasticsearch(es_ip + ':' + es_port)
    '''log紀錄執行狀況'''
    global logsFunction
    logsFunction = LogsFunc("exploitdb")
    get_exploitdb(chormdriver_path)

if __name__ == '__main__':
    run()